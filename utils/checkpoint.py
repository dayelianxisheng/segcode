"""
æ¨¡å‹æ£€æŸ¥ç‚¹ç®¡ç†
æ”¯æŒä¿å­˜æœ€ä½³æ¨¡å‹ã€æ—©åœã€æ–­ç‚¹ç»­è®­
"""
import os
import torch
import shutil


def save_checkpoint(model, optimizer, epoch, loss, is_best=False, filepath='checkpoint.pth', best_val_loss=None):
    """
    ä¿å­˜æ£€æŸ¥ç‚¹

    Args:
        model: æ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨
        epoch: å½“å‰epoch
        loss: å½“å‰loss
        is_best: æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹
        filepath: ä¿å­˜è·¯å¾„
        best_val_loss: æœ€ä½³éªŒè¯loss
    """
    checkpoint = {
        'epoch': epoch,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': loss,
    }

    if best_val_loss is not None:
        checkpoint['best_val_loss'] = best_val_loss

    torch.save(checkpoint, filepath)

    if is_best:
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        best_filepath = filepath.replace('.pth', '_best.pth')
        shutil.copy(filepath, best_filepath)


def load_checkpoint(filepath, model, optimizer=None):
    """
    åŠ è½½æ£€æŸ¥ç‚¹

    Args:
        filepath: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        model: æ¨¡å‹
        optimizer: ä¼˜åŒ–å™¨ï¼ˆå¯é€‰ï¼‰

    Returns:
        start_epoch: å¼€å§‹epoch
    """
    if not os.path.exists(filepath):
        print(f"âš ï¸  æ£€æŸ¥ç‚¹ä¸å­˜åœ¨: {filepath}")
        return 0

    print(f"ğŸ“‚ åŠ è½½æ£€æŸ¥ç‚¹: {filepath}")
    checkpoint = torch.load(filepath, map_location='cpu')

    model.load_state_dict(checkpoint['model_state_dict'])

    if optimizer is not None and 'optimizer_state_dict' in checkpoint:
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

    start_epoch = checkpoint['epoch'] + 1
    loss = checkpoint.get('loss', 0)

    print(f"   Epoch: {checkpoint['epoch']}, Loss: {loss:.4f}")
    print(f"   å°†ä»epoch {start_epoch}ç»§ç»­è®­ç»ƒ")

    return start_epoch


class EarlyStopping:
    """æ—©åœæœºåˆ¶"""
    def __init__(self, patience=10, min_delta=0.0, mode='min'):
        """
        Args:
            patience: å®¹å¿epochæ•°
            min_delta: æœ€å°æ”¹å–„å¹…åº¦
            mode: 'min' æˆ– 'max'
        """
        self.patience = patience
        self.min_delta = min_delta
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.early_stop = False

    def __call__(self, current_score):
        """
        Args:
            current_score: å½“å‰éªŒè¯æŒ‡æ ‡

        Returns:
            æ˜¯å¦åº”è¯¥æ—©åœ
        """
        if self.best_score is None:
            self.best_score = current_score
            self.counter = 0
        else:
            if self.mode == 'min':
                improved = current_score < self.best_score - self.min_delta
            else:
                improved = current_score > self.best_score + self.min_delta

            if improved:
                self.best_score = current_score
                self.counter = 0
            else:
                self.counter += 1
                if self.counter >= self.patience:
                    self.early_stop = True
                    print(f"  æ—©åœè§¦å‘: {self.patience}ä¸ªepochæ— æ”¹å–„")

        return self.early_stop


if __name__ == '__main__':
    # æµ‹è¯•æ—©åœ
    print("=" * 60)
    print("æµ‹è¯•æ—©åœæœºåˆ¶")
    print("=" * 60)

    early_stopping = EarlyStopping(patience=3, min_delta=0.01)

    scores = [0.8, 0.75, 0.72, 0.71, 0.70, 0.69, 0.68]

    for epoch, score in enumerate(scores, 1):
        print(f"\nEpoch {epoch}: Score = {score:.4f}")
        if early_stopping(score):
            print(f" åœæ­¢è®­ç»ƒï¼ˆåœ¨epoch {epoch}ï¼‰")
            break
        else:
            print(f"   ç»§ç»­è®­ç»ƒï¼ˆcounter: {early_stopping.counter}/{early_stopping.patience}ï¼‰")

    print(f"\næœ€ä½³åˆ†æ•°: {early_stopping.best_score:.4f}")
